%!TEX root = mb.tex


\section{Header-only middleboxes}




\subsection{Middlebox: Firewall}\label{sec:firewall}


We use the term ``firewall'' for stateful and stateless packet filters that filter the traffic based on network layers and transport layers. Stateless firewalls commonly examine the combination of the packet's source and destination address, its protocol, and for TCP/ UDP traffic, its source and destination port number. Stateful firewalls additionally keep track of protocol states for each flow and retain packets until they have enough information to make decision. 
Our RangeMatch scheme supports both types of firewalls. We now explain the design of the firewall based on this scheme.

\mypara{Setup} Initially, the gateway (G) encrypts the rules to be used by the firewall, by encrypting all IP addresses and ports in the rules, as follows.

First, it prepares the IP and port intervals. Recall that RangeMatch requires the IP addresses to be IPv6 to guarantee the injectivity of encryption (see \S\ref{sec:range}); hence, we extend an IPv4 prefix  such as 157.161.48.0/24 to an IPv6 one  ::ffff:157.161.48.0/120. 
% Now the prefix represents the range from ::ffff:157.161.48.0 to ::ffff:157.161.48.255.
 This problem does not show up for ports because they only need to be distinct within the same IP address.
The gateway then expands every prefix into an interval, and every exact match $x$ into [$x$, $x$]. 

Next, the gateway encrypts these intervals using EncryptRanges (\S\ref{sec:range}) by running one instance of RangeMatch for IP addresses and one instance for ports.
It then convets each encrypted IP range into a set of prefixes and duplicates the rule for each prefix in this set. 

Consider an example rule from  \mf{pf}, the 
default firewall under BSD:
 \mf{ block out log quick on \$ext\_if from} \\ \mf{157.161.48.0/24 to any.}
Let the encryption of 157.161.48.0/24 be the interval [80.0.0.0, 160.0.0.0] (for brevity, we use IPv4). 
This interval is equivalent to the prefixes: 80.0.0.0/4, 96.0.0.0/3, 144.0.0.0/4, and 160.0.0.0/32. 
Hence, the gateway replaces the original rule with four rules, one for each encrypted prefix. 
The worst-case number of prefixes for IPv6 is $O$($\min$($\log$ number of rules, $128$)) = $O$($\log$ number of rules), 
which is small. 


% Firewalls from different vendors may vary significantly in terms of rule syntaxes and organizations. However,
% in general both hardware and software firewalls have a few interfaces. Both ingress and egress of an interface 
% can be associated with an access control list (ACL). Each ACL has a number of rules, possibly in the form 
% <action, protocol, src ip, src port, dst ip, dst port>. Without loss of generality, we take \mf{pf}, the 
% default firewall under BSD, as an example to illustrate how \sys works with firewalls. Figure \ref{fig:fwrule1} 
% shows an example of \mf{pf} rules. 





The gateway sends the new rules to the service provider (SP) which installs them into the firewall {\em the same way it would install 
them if they were not encrypted}. 

\mypara{Processing traffic}
When a packet arrives at the gateway, the gateway encrypts its source/destination IP addresses and ports using the EncryptValue algorithm
and fits these into the packet header because RangeMatch is format preserving.
For example, for an IP address $v$, EncryptValue produces $\enc(v)$ and $\IV, \aes_k(\IV, v)$.
 $\enc(v)$ preserves the format of an IP address and hence 
it will fit in the packet header in the place of the unencrypted IP address. $\IV, \aes_k(\IV, v)$ is placed in the packet's options header as in Fig.~\ref{fig:packet}.

The gateway sends the packet to the firewall. The firewall can execute on the encrypted header {\em
the same way as on the unencrypted header} because RangeMatch maintains the order relation between values in rules and in 
packet headers. 
In particular, it can use any of the existing fast matching algorithms unchanged. 
Moreover, it can still use  any specialized hardware without changes. This property is important, since many high-speed firewalls are implemented in hardware, which is difficult and expensive to redesign.


\mypara{Updating rules} 
Let us discuss the case of adding a new firewall rule; deleting a rule is similar.
The gateway runs AddRange from \S\ref{s:rangealg}. This produces a new encrypted range [$\enc(s), \enc(e)$] 
along with a list $L$ of other encrypted ranges that get updated. 
The gateway computes the new rule(s) based on [$\enc(s), \enc(e)$] as well as a list of prefix changes based on $L$: this list maps old prefix to new prefix so that the firewall knows how to update its rules. 
The gateway sends the new rules and prefix changes to the firewall, and the firewall reconfigures itself. 
  Due to the guarantees of our RangeMatch protocol, this list contains a 
small number (logarithmic) of intervals that changed, so the overhead for the reconfiguration should be modest.


\mypara{Rules updates affect other middleboxes}
Since some encrypted ranges shifted, a previously encrypted IP address might now match into a wrong interval. 
This affects all the middleboxes that retained an encrypted IP address.

To address this, the gateway also computes $\mathbb{I}$, the interval that encloses all the changes.
This interval is computed by simply taking the minimum and maximum encrypted value in the list $L$ or [$\enc(s)$, $\enc(e)$].
The gateway sends $\mathbb{I}$ to {\em every middlebox} at SP. 
 
 
We now discuss what the firewall and other middleboxes do with $\mathbb{I}$.


\subsection{Updating ranges}

Consider that a header-only middlebox MB receives the interval $\mathbb{I}$ from the gateway indicating a change of ranges. If MB has an IP address $v$ encrypted in the past and $v$ falls in $\mathbb{I}$, $v$ has become stale.  As a result,  MB sends the list of these IP addresses to the gateway along with their AES encryption (which MB should have retained when first receiving a packet with this IP address or port). The gateway remaps them to new encrypted values and sends them back to MB which updates them. 


Such adjustment of encryptions are necessary for an encryption scheme like RangeMatch, as discussed in \S\ref{sec:range}. Nevertheless, this operation happens rarely and is not expensive: it happens only when firewall rules change and the number of ranges changed is  amortized logarithmic.
Moreover, \S\ref{sec:impl} describes how these updates are performed efficiently. 
 



\subsection{Middlebox: NAT}\label{sec:nat}

\todo{give example for NAT}

The fast path of the NAT in \sys{} is unchanged from the regular NAT. The NAT maps IP addresses/ports that are encrypted to external IP addresses/ports 
as if they were not encrypted, as in Fig.~\ref{fig:packetflow}. 

The difference is  when the firewall sends a list of range changes $L$ and maybe a new interval  [$\enc(s), \enc(e)$] .
The NAT identifies all  encrypted IP addresses/ports  it has mapped that are affected: it computes an interval that covers all intervals in $L$ and $\enc(s), \enc(e)$ and checks which values fit in it. It then sends these values to the gateway, who reencrypts them using EncryptValue (\S\ref{s:rangealg}) so the NAT updates them. 

Such adjustment of encryptions are necessary for an encryption scheme like RangeMatch, as discussed in \S\ref{sec:range}. Nevertheless, this operation happens rarely and is not expensive: it happens only when firewall rules change and the number of ranges changed is  amortized logarithmic.


\subsection{Middlebox: Proxy/cache}\label{s:proxy}

The proxy  caches HTTP static content (e.g., images) in order to improve client-side performance. 
When a client opens a new HTTP connection, a typical proxy will capture the client's SYN packet and open a new connection to the client, as if the proxy were the web server. The proxy then opens a second connection in the background to the original web server, as if it were the client. 
When a client sends a request for new content, if the content is in the proxy's cache, the proxy will serve it from there. Otherwise, the proxy will forward this request to the web server and cache the new content. 
\sys supports the proxy as follows. 

\mypara{Encryption at the gateway} The gateway parses the HTTP header in a packet's payload to identify the file path $F$ in a ``GET'' request. 
This is easy to do because the header appears at the start of the payload. For this task, the gateway does negligible work, resulting in less than 1\% throughput loss over the RangeMatch encryption. 
Next, the gateway encrypts $F$ using the KeywordMatch scheme. In this case, it can use the deterministic version (discussed in~\S\ref{s:kwmatch}) with no reduction in security because the proxy caches a set of {\em unique} file paths. Hence, using this scheme, the gateway encrypts $F$ into $\aes_k(F)$ and places it into the options header as in Fig.~\ref{fig:packet}. 
Even though it examines the packet's payload, the gateway does not need per-connection state and can parse the HTTP header fast, so it still fits in the header-only middleboxes. 

\mypara{Processing at the proxy} The proxy has a map of encrypted file path to encrypted file content. When the proxy receives a packet, the proxy extracts $\aes_k(F)$ from the options header and looks it up in the cache {\em as if it were not encrypted}. The use of deterministic encryption enables the proxy to use a fast search data structure/index, such as a hash map, unchanged. We have two cases: there is a hit or a miss. For hit, the proxy assembles a packet header for reverse traffic and attaches to it the encrypted file content from the cache. Even without being able to encrypt IP addresses or ports, the proxy can create the header by reversing the encrypted information in the original header.
For miss, the proxy forwards the request to the web server. When receiving the response, the proxy caches it for file path $\aes_k(F)$ to serve future requests.

We can extend our proxy support to HTTP pipelining. %some connections bundle together in the same stream a bunch of HTTP requests. 
In this case,  an HTTP header may no longer appear at the beginning of a packet and it can appear in the middle of the packet or across packet boundaries. We do not give the details of our solution here, but at a high level, one can use the IDS approach in \S\ref{sec:ids} to enable the web proxy to search for keywords on the payload  (effectively parsing the HTTP header over encrypted data) and identify the encrypted file path. In this case though, \sys can no longer support the web proxy in the header-only mode; it becomes a bytestream-aware application. 


%SOME POTENTIALLY USEFUL INFO
%
%we are focusing on the transparent proxy
%- discuss the kind of proxies we are focusing on
%
%proxies have two benefits: latency savings which aplomb gives you 
%and bandwidth savings, which aplomb does nogive you
% 
%L7 Proxy / Cache
%
%With pipelined requests, we don't have the header is always the first part of the packet. Instead, we need to {\it reconstruct the payload} to tell where to parse. This is where we need to use the other gatway. Otherwise, the functionality is exactly the same above -- only now we operate on the reconstructed payload rather than the first few bytes of the first packet.
%









%When a client initiates a connection to a web server, the proxy {\it terminates} the connection instead of allowing packets to ``pass through''.
%
%
%However, rather than encrypting fixed values at fixed locations, the \sys gateway parses the HTTP header to determine what data to encrypt.
%Nevertheless, as we show in \S\ref{sec:eval}, this parsing has a negligible overhead on gateway throughput -- less than 1\% when added in addition to the existing encryption required for Firewalling and NAT.
%We implement two versions of gateway encryption: one which uses the stateless gateway and can encode HTTP requests which are not pipelined, and one which uses the stateful gateway, which supports pipelined HTTP requests as well (we discuss the difference as follows).




